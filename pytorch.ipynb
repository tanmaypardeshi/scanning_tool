{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "873716ff",
   "metadata": {},
   "source": [
    "# Running ModelScan on a Pytorch Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63233445",
   "metadata": {},
   "source": [
    "## Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede2db21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from utils.pytorch_sentiment_model import download_model, predict_sentiment\n",
    "from utils.pickle_codeinjection import PickleInject, get_payload\n",
    "\n",
    "%env TOKENIZERS_PARALLELISM=false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc17f2a",
   "metadata": {},
   "source": [
    "## Download and save the model\n",
    "\n",
    "We are going to use a BERT based sentiment analysis PyTorch model (https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment). This safe model will get saved at `./PyTochModels/safe_model.pt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecea198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a model for sentiment analysis\n",
    "from typing import Final\n",
    "\n",
    "model_directory: Final[str] = \"PyTorchModels\"\n",
    "if not os.path.isdir(model_directory):\n",
    "    os.mkdir(model_directory)\n",
    "\n",
    "safe_model_path = os.path.join(model_directory, \"safe_model.pt\")\n",
    "\n",
    "download_model(safe_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f316d16",
   "metadata": {},
   "source": [
    "## Run the model\n",
    "\n",
    "Run the safe model to verify that it has been downloaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68770a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = predict_sentiment(\n",
    "    \"Stock market was bearish today\", torch.load(safe_model_path)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66644ce5",
   "metadata": {},
   "source": [
    "## Run ModelScan on the safe model\n",
    "\n",
    "Now run the Modelscan tool using the modelscan command. Remember that we installed modelscan in our virtualenv. \n",
    "\n",
    "**The scan results include information on the files scanned, and any issues if found. For the safe model scanned, modelscan finds no model serialization attacks.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bc3c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "!modelscan --path PyTorchModels/safe_model.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb6fd80",
   "metadata": {},
   "source": [
    "## Model Serialization Attack\n",
    "\n",
    "Now we inject some malicious code into the safe model and save it in a new model `./PyTorchModels/unsafe_model.pt`. \n",
    "\n",
    "The code we are injecting is to read aws secret keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c33e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"system\"\n",
    "malicious_code = \"\"\"cat ~/.aws/secrets\n",
    "    \"\"\"\n",
    "\n",
    "unsafe_model_path = os.path.join(model_directory, \"unsafe_model.pt\")\n",
    "\n",
    "payload = get_payload(command, malicious_code)\n",
    "torch.save(\n",
    "    torch.load(safe_model_path),\n",
    "    f=unsafe_model_path,\n",
    "    pickle_module=PickleInject([payload]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a21a7b",
   "metadata": {},
   "source": [
    "## Unsafe Model Prediction\n",
    "\n",
    "The malicious code injected in the unsafe model gets executed when it is loaded. \n",
    "\n",
    "You can see in the output that the aws secret keys are displayed. \n",
    "\n",
    "Also, the unsafe model predicts the sentiments just as well as safe model i.e. the code injection will not impact the model performance. The unaffected performance of unsafe models makes the ML models an effective attack vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d883c542",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sentiment(\"Stock market was bearish today\", torch.load(unsafe_model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779f6b43",
   "metadata": {},
   "source": [
    "## Run ModelScan on the unsafe model\n",
    "\n",
    "The scan results include information on the files scanned, and any issues if found. In this case, a critical severity level issue is found in the unsafe model scanned.\n",
    "\n",
    "modelscan also outlines the found operator(s) and module(s) deemed unsafe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e813260",
   "metadata": {},
   "outputs": [],
   "source": [
    "!modelscan --path  ./PyTorchModels/unsafe_model.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a27ca8e",
   "metadata": {},
   "source": [
    "## Change the reporting format of output\n",
    "\n",
    "This will save the scan results in the file: pytorch-model-scan-results.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fd61b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!modelscan --path  ./PyTorchModels/unsafe_model.pt -r json -o pytorch-model-scan-results.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
