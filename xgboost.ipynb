{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "873716ff",
   "metadata": {},
   "source": [
    "# Running ModelScan on a XGBoost Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63233445",
   "metadata": {},
   "source": [
    "## Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede2db21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "from utils.pickle_codeinjection import generate_unsafe_file\n",
    "from utils.xgboost_diabetes_model import train_model, get_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc17f2a",
   "metadata": {},
   "source": [
    "## Download and save the model\n",
    "\n",
    "The model is trained on a diabetes dataset, and predicts whether a person has diabetes or not (https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database). The model is saved at ./XGBoostModels/safe_model.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecea198",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = os.path.join(os.getcwd(), \"XGBoostModels\")\n",
    "if not os.path.isdir(model_directory):\n",
    "    os.mkdir(model_directory)\n",
    "\n",
    "safe_model_path_pickle = os.path.join(model_directory, \"safe_model.pkl\")\n",
    "model = train_model()\n",
    "with open(safe_model_path_pickle, \"wb\") as fo:\n",
    "    pickle.dump(model, fo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f316d16",
   "metadata": {},
   "source": [
    "## Run the model\n",
    "\n",
    "Run the safe model to verify that it has been downloaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68770a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_predictions = 3\n",
    "get_predictions(number_of_predictions, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66644ce5",
   "metadata": {},
   "source": [
    "## Run ModelScan on the safe model\n",
    "\n",
    "Now run the Modelscan tool using the modelscan command. Remember that we installed modelscan in our virtualenv. \n",
    "\n",
    "**The scan results include information on the files scanned, and any issues if found. For the safe model scanned, modelscan finds no model serialization attacks.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bc3c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "!modelscan -p XGBoostModels/safe_model.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb6fd80",
   "metadata": {},
   "source": [
    "## Model Serialization Attack\n",
    "\n",
    "Here code is injected in the safe model to read aws secret keys. The unsafe model is saved at `./XGBoostModels/unsafe_model.pkl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f016506",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"system\"\n",
    "malicious_code = \"\"\"cat ~/.aws/secrets\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f675be07",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(safe_model_path_pickle, \"rb\") as fo:\n",
    "    safe_model_pickle = pickle.load(fo)\n",
    "\n",
    "unsafe_model_path = os.path.join(model_directory, \"unsafe_model.pkl\")\n",
    "generate_unsafe_file(model, command, malicious_code, unsafe_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a21a7b",
   "metadata": {},
   "source": [
    "## Run the unsafe model\n",
    "\n",
    "The malicious code injected in the unsafe model gets executed when it is loaded. The aws secret keys are displayed.\n",
    "\n",
    "Also, the unsafe model predicts the clothing items just as well as safe model i.e., the code injection attack will not impact the model performance. The unaffected performance of unsafe models makes the ML models an effective attack vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13f0de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(unsafe_model_path, \"rb\") as fo:\n",
    "    unsafe_model = pickle.load(fo)\n",
    "\n",
    "get_predictions(number_of_predictions, unsafe_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779f6b43",
   "metadata": {},
   "source": [
    "## Run ModelScan on the unsafe model\n",
    "\n",
    "The scan results include information on the files scanned, and any issues if found. In this case, a critical severity level issue is found in the unsafe model scanned.\n",
    "\n",
    "modelscan also outlines the found operator(s) and module(s) deemed unsafe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e813260",
   "metadata": {},
   "outputs": [],
   "source": [
    "!modelscan -p XGBoostModels/unsafe_model.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a27ca8e",
   "metadata": {},
   "source": [
    "## Change the reporting format of output\n",
    "\n",
    "This will save the scan results in file: xgboost-model-scan-results.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fd61b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!modelscan --path  XGBoostModels/unsafe_model.pkl -r json -o xgboost-model-scan-results.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
